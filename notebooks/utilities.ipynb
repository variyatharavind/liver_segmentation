{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    AddChanneld,\n",
    "    LoadImaged,\n",
    "    Resized,\n",
    "    ToTensord,\n",
    "    Spacingd,\n",
    "    Orientationd,\n",
    "    ScaleIntensityRanged,\n",
    "    CropForegroundd\n",
    ")\n",
    "from monai.data import DataLoader, Dataset, CacheDataset\n",
    "from monai.utils import set_determinism, first\n",
    "from monai.losses import DiceLoss\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test_split(data_path, test_size=0.2, random_state=0):\n",
    "    images = np.array(sorted(glob(os.path.join(data_path, 'images/*'))))\n",
    "    labels = np.array(sorted(glob(os.path.join(data_path, 'labels/*'))))\n",
    "    train_images, test_images, train_labels, test_labels = train_test_split(images, labels, test_size = test_size, random_state = random_state)\n",
    "    return { 'train_images': train_images, 'test_images': test_images, 'train_labels': train_labels, 'test_labels' : test_labels }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Input Transforms and Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(files, pixdim=(1.5, 1.5, 1.0), a_min=-200, a_max=200, spatial_size=[128, 128, 64], cache=False):\n",
    "    \n",
    "    set_determinism(seed = 0)\n",
    "\n",
    "    train_files = [{'images': image_name, 'labels': label_name} for image_name, label_name in zip(files['train_images'], files['train_labels'])]\n",
    "    test_files = [{'images': image_name, 'labels': label_name} for image_name, label_name in zip(files['test_images'], files['test_labels'])]\n",
    "\n",
    "    train_transforms = Compose(\n",
    "        [\n",
    "            LoadImaged(keys=['images', 'labels']),\n",
    "            AddChanneld(keys=['images', 'labels']),\n",
    "            Spacingd(keys=['images', 'labels'], pixdim=pixdim, mode=('bilinear', 'nearest')),\n",
    "            Orientationd(keys=['images', 'labels'], axcodes='RAS'),\n",
    "            ScaleIntensityRanged(keys=['images'], a_min=a_min, a_max=a_max, b_min=0, b_max=1, clip=True),\n",
    "            CropForegroundd(keys=['images', 'labels'], source_key='images'),\n",
    "            Resized(keys=['images', 'labels'], spatial_size=spatial_size),\n",
    "            ToTensord(keys=['images', 'labels'])\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    test_transforms = Compose(\n",
    "        [\n",
    "            LoadImaged(keys=['images', 'labels']),\n",
    "            AddChanneld(keys=['images', 'labels']),\n",
    "            Spacingd(keys=['images', 'labels'], pixdim=pixdim, mode=('bilinear', 'nearest')),\n",
    "            Orientationd(keys=['images', 'labels'], axcodes='RAS'),\n",
    "            ScaleIntensityRanged(keys=['images'], a_min=a_min, a_max=a_max, b_min=0, b_max=1, clip=True),\n",
    "            CropForegroundd(keys=['images', 'labels'], source_key='images'),\n",
    "            Resized(keys=['images', 'labels'], spatial_size=spatial_size),\n",
    "            ToTensord(keys=['images', 'labels'])\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    if cache:\n",
    "        train_ds = CacheDataset(data=train_files, transform=train_transforms, cache_rate=1.0)\n",
    "        test_ds = CacheDataset(data=test_files, transform=test_transforms, cache_rate=1.0)\n",
    "\n",
    "    else:\n",
    "        train_ds = Dataset(data=train_files, transform=train_transforms)\n",
    "        test_ds = Dataset(data=test_files, transform=test_transforms)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=1)\n",
    "    test_loader = DataLoader(test_ds, batch_size=1)\n",
    "\n",
    "    return train_loader, test_loader\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display a slice of the first patient data sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_patient(data, SLICE_NUMBER=1, train=True, test=False):\n",
    "    \n",
    "    check_patient_train, check_patient_test = data\n",
    "\n",
    "    view_train_patient = first(check_patient_train)\n",
    "    view_test_patient = first(check_patient_test)\n",
    "\n",
    "    if train:\n",
    "        plt.figure(\"Train Visualisation\", (12, 6))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.title(f'image {SLICE_NUMBER}')\n",
    "        plt.imshow(view_train_patient['images'][0, 0, :, :, SLICE_NUMBER], cmap='gray')\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.title(f'label {SLICE_NUMBER}')\n",
    "        plt.imshow(view_train_patient['labels'][0, 0, :, :, SLICE_NUMBER])\n",
    "        plt.show()\n",
    "\n",
    "    if test:\n",
    "        plt.figure(\"Test Visualisation\", (12, 6))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.title(f'image {SLICE_NUMBER}')\n",
    "        plt.imshow(view_test_patient['images'][0, 0, :, :, SLICE_NUMBER], cmap='gray')\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.title(f'label {SLICE_NUMBER}')\n",
    "        plt.imshow(view_test_patient['labels'][0, 0, :, :, SLICE_NUMBER])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate number of pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pixels(data):\n",
    "    \n",
    "    val = np.zeros((1,2))\n",
    "    \n",
    "    for batch in tqdm(data):\n",
    "        batch_label = batch[\"labels\"] != 0\n",
    "        _, count = np.unique(batch_label, return_counts=True)\n",
    "        \n",
    "        if len(count) == 1:\n",
    "            count = np.append(count, 0)\n",
    "        val += count\n",
    "\n",
    "    val = val // 1e7\n",
    "    print(val)\n",
    "\n",
    "    return val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate weights for Cross Entropy Loss using counts of foreground and background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weights(count):\n",
    "\n",
    "    total = count.sum()\n",
    "    weights = count / total\n",
    "    weights = 1 / weights\n",
    "    total = weights.sum()\n",
    "    weights = weights / total\n",
    "    \n",
    "    return torch.tensor(weights, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the Dice Metric to evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_metric(predicted, target):\n",
    "    dice_value = DiceLoss(to_onehot_y=True, sigmoid=True, squared_pred=True)\n",
    "    value = 1 - dice_value(predicted, target).item()\n",
    "    return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_in, loss, optim, max_epochs, model_dir, test_interval=1, load=False, path='', device=torch.device(\"cuda:0\")):\n",
    "    \n",
    "    best_metric = -1\n",
    "    best_metric_epoch = -1\n",
    "\n",
    "    save_loss_train = []\n",
    "    save_loss_test = []\n",
    "    save_metric_train = []\n",
    "    save_metric_test = []\n",
    "\n",
    "    train_loader, test_loader = data_in\n",
    "\n",
    "    cur_epoch = 0\n",
    "\n",
    "    if load:\n",
    "        checkpoint = torch.load(os.path.join(model_dir, \"best_metric_model.pth\"))\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optim.load_state_dict(checkpoint['optim_state_dict'])\n",
    "        cur_epoch = checkpoint['epoch']\n",
    "\n",
    "    for epoch in range(cur_epoch, max_epochs):\n",
    "        print(\"-\" * 10)\n",
    "        print(f\"epoch {epoch+1}/{max_epochs}\")\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        train_step = 0\n",
    "        train_epoch_loss = 0\n",
    "        train_epoch_metric = 0\n",
    "\n",
    "        for batch_data in train_loader:\n",
    "            train_step += 1\n",
    "\n",
    "            image = batch_data[\"images\"]\n",
    "            label = batch_data[\"labels\"]\n",
    "            label = label != 0\n",
    "            image, label = (image.to(device), label.to(device))\n",
    "\n",
    "            optim.zero_grad()\n",
    "            outputs = model(image)\n",
    "            \n",
    "            train_loss = loss(outputs, label)\n",
    "\n",
    "            train_loss.backward()\n",
    "            optim.step()\n",
    "\n",
    "            train_epoch_loss += train_loss.item()\n",
    "\n",
    "            train_metric = dice_metric(outputs, label)\n",
    "            train_epoch_metric += train_metric\n",
    "\n",
    "            print(f'{train_step}/{len(train_loader) // train_loader.batch_size}  '\n",
    "                f'train_loss: {train_loss.item():.4f}, train_dice: {train_metric:.4f}')\n",
    "\n",
    "        print('-'*20)\n",
    "\n",
    "        train_epoch_loss /= train_step\n",
    "        print(f'epoch_loss: {train_epoch_loss:.4f}')\n",
    "        save_loss_train.append(train_epoch_loss)\n",
    "        np.save(os.path.join(model_dir, 'loss_train.npy'), save_loss_train)\n",
    "\n",
    "        train_epoch_metric /= train_step\n",
    "        print(f'epoch_metric: {train_epoch_metric:.4f}')\n",
    "        save_metric_train.append(train_epoch_metric)\n",
    "        np.save(os.path.join(model_dir, 'metric_train.npy'), save_metric_train)\n",
    "\n",
    "        if (epoch + 1) % test_interval == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                test_step = 0\n",
    "                test_epoch_loss = 0\n",
    "                test_epoch_metric = 0\n",
    "                \n",
    "                for test_data in test_loader:\n",
    "\n",
    "                    test_step += 1\n",
    "\n",
    "                    test_image = test_data[\"images\"]\n",
    "                    test_label = test_data[\"labels\"]\n",
    "                    test_label = test_label != 0\n",
    "                    test_image, test_label = (test_image.to(device), test_label.to(device))\n",
    "\n",
    "                    test_outputs = model(test_image)\n",
    "\n",
    "                    test_loss = loss(test_outputs, test_label)\n",
    "                    test_epoch_loss += test_loss.item()\n",
    "                    test_metric = dice_metric(test_outputs, test_label)\n",
    "                    test_epoch_metric += test_metric\n",
    "\n",
    "                test_epoch_loss /= test_step\n",
    "                print(f'test_loss_epoch: {test_epoch_loss:.4f}')\n",
    "                save_loss_test.append(test_epoch_loss)\n",
    "                np.save(os.path.join(model_dir, 'loss_test.npy'), save_loss_test)\n",
    "\n",
    "                test_epoch_metric /= test_step\n",
    "                print(f'test_dice_epoch: {test_epoch_metric:.4f}')\n",
    "                save_metric_test.append(test_epoch_metric)\n",
    "                np.save(os.path.join(model_dir, 'metric_test.npy'), save_metric_test)\n",
    "\n",
    "                if test_epoch_metric > best_metric:\n",
    "                    best_metric = test_epoch_metric\n",
    "                    best_metric_epoch = epoch + 1\n",
    "\n",
    "                    torch.save({\n",
    "                        'epoch': best_metric_epoch, \n",
    "                        'model_state_dict': model.state_dict(),\n",
    "                        'optim_state_dict': optim.state_dict()\n",
    "                    }, os.path.join(model_dir, \"best_metric_model.pth\"))\n",
    "\n",
    "                print(\n",
    "                    f\"current epoch: {epoch + 1} current mean dice: {test_metric:.4f}\\n\"\n",
    "                    f\"best mean dice: {best_metric:.4f} \"\n",
    "                    f\"at epoch: {best_metric_epoch}\"\n",
    "                )"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f5da73322900ad9585fd353449d400c52830a069bc5c320cb6da3eb6774a165a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('liver_segmentation': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
